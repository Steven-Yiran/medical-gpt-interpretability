{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:06<00:00,  1.16it/s]\n",
      "  0%|          | 0/1046 [00:00<?, ?it/s]/home/ubuntu/research-1/medical-gpt-interpretability/ENV/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      " 27%|██▋       | 281/1046 [12:03<32:36,  2.56s/it]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"epfl-llm/meditron-7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load evaluation dataset\n",
    "with open('gender_biased_data.json', 'r') as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "def format_prompt(question, options):\n",
    "    system = \"You are a medical doctor taking the US Medical Licensing Examination. You need to demonstrate your understanding of basic and clinical science, medical knowledge, and mechanisms underlying health, disease, patient care, and modes of therapy. Show your ability to apply the knowledge essential for medical practice. For the following multiple-choice question, select one correct answer from A to D. Base your answer on the current and standard practices referenced in medical guidelines.\"\n",
    "    question = f\"Question: {question}\\n\\nOptions:\\n\"\n",
    "    for i, option in enumerate(options):\n",
    "        letter = chr(65 + i)  # Convert 0-based index to A, B, C, D\n",
    "        question += f\"{letter}. {option}\\n\"\n",
    "    question += \"The answer is:\"\n",
    "    return f\"System: {system}\\n\\n{question}\"\n",
    "\n",
    "def generate_answer(question, options, max_length=512):\n",
    "    # Use format_prompt to generate the prompt\n",
    "    prompt = format_prompt(question, options)\n",
    "    prompt_lz = len(prompt)\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Generate only one token after the prompt\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.001, # 0.7, 0.5, 0.1, 0.001\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    token_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return token_text[prompt_lz:]\n",
    "\n",
    "# Evaluation metrics\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Evaluation results storage\n",
    "outs = []\n",
    "\n",
    "# Evaluate model on each question\n",
    "for item in tqdm(eval_data):\n",
    "    question = item['Original Question']\n",
    "    options = item['Original Options']\n",
    "    correct_label = item['Label']\n",
    "    question_id = item['ID']\n",
    "    \n",
    "    # Generate model's answer\n",
    "    output = generate_answer(question, options)\n",
    "\n",
    "    outs.append({\n",
    "        'ID': question_id,\n",
    "        'Original Question': question,\n",
    "        'Original Options': options,\n",
    "        'Label': correct_label,\n",
    "        'Generated Answer': output\n",
    "    })\n",
    "\n",
    "\n",
    "# save the results to a json file\n",
    "with open('meditron_results.json', 'w') as f:\n",
    "    json.dump(outs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
